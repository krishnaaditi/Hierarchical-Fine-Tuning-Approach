# Hierarchical-Fine-Tuning-Approach
Multimodal Large Language Model (MLLM): LLMs that processes and understands multiple
modalities of data, such as text, images, video, etc. instead of just text like traditional LLMs.
MLLMs often generate hallucinationsâ€”fabricated or incorrect information that does not
match visual input.
There is a modality gap between textual and visual representations, leading to misalignment.
Hallucinative and non-hallucinative texts are entangled, making it difficult to differentiate
them.
Existing methods fail to effectively bridge the vision-language gap, increasing the
occurrence of hallucinations.


