# Hierarchical-Fine-Tuning-Approach
Motivation 
Multimodal Large Language Model (MLLM): LLMs that processes and understands multiple
modalities of data, such as text, images, video, etc. instead of just text like traditional LLMs.
MLLMs often generate hallucinationsâ€”fabricated or incorrect information that does not
match visual input.
There is a modality gap between textual and visual representations, leading to misalignment.
Hallucinative and non-hallucinative texts are entangled, making it difficult to differentiate
them.
Existing methods fail to effectively bridge the vision-language gap, increasing the
occurrence of hallucinations.


![image](https://github.com/user-attachments/assets/2a0d2fe4-48c5-4bc9-988c-f3b2c1402b25)
